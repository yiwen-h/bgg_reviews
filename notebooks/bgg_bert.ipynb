{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df50e3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97885, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/clean_data.csv')\n",
    "df = df[['comment', 'rating']].drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aca9d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92261, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df_eng = df[df['comment'].apply(isEnglish)]\n",
    "df_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de2ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_eng['comment']\n",
    "y = df_eng['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb5d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     play once didnt like\n",
       "1        several thing dislike player elimination which...\n",
       "2        seem like ok game but doesnt really work for o...\n",
       "3           flux munchkin mix but bad way way way too long\n",
       "4        the game open the player sieged by group ease ...\n",
       "                               ...                        \n",
       "99994    at heart scrabble variant like more than scrab...\n",
       "99995    get little more familiar with realize make gam...\n",
       "99996    fun fast clever game feel like tricktaking gam...\n",
       "99998    nice one first off buy play solitaire but the ...\n",
       "99999    kid rat daughter enjoy one lot improvement ove...\n",
       "Name: comment, Length: 92261, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "\n",
    "def clean (text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word, pos = 'n') for word in words_only] # Lemmatize\n",
    "    lemmatized1 = [lemma.lemmatize(word, pos = 'v') for word in lemmatized] # Lemmatize\n",
    "    lemmatized2 = [lemma.lemmatize(word, pos = 'a') for word in lemmatized1] # Lemmatize\n",
    "    lemmatized3 = [lemma.lemmatize(word, pos = 'r') for word in lemmatized2] # Lemmatize\n",
    "    stop_words = ['it', 'and', 'an', 'a', 'my', 'this', 'that', 'to', 'be', 'is', 'i', 'you'] # Make stopword list\n",
    "    without_stopwords = [word for word in lemmatized3 if not word in stop_words] \n",
    "    back_into_string = ' '.join(without_stopwords)\n",
    "    return back_into_string\n",
    "\n",
    "# Apply to all texts\n",
    "clean_X = X.apply(clean)\n",
    "clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a287218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f88f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
